import streamlit as st
import pandas as pd
import requests
import re
import time

# ç¶²é è¨­å®š
st.set_page_config(page_title="FB è¼•é‡åŒ–æŒ‰è®šæŠ“å–å·¥å…·", layout="centered")

st.title("ğŸš€ FB å…¬é–‹è²¼æ–‡æŒ‰è®šçµ±æ•´ (è¼•é‡ç‰ˆ)")
st.info("æ­¤ç‰ˆæœ¬ä¿®å¾©äº†ç¶²å€è§£æéŒ¯èª¤ï¼Œè«‹ç¢ºä¿è¼¸å…¥çš„é€£çµæ˜¯å…¬é–‹è²¼æ–‡ã€‚")

# è¼¸å…¥å€
urls_input = st.text_area("è«‹è²¼å…¥ Facebook é€£çµ (æ¯è¡Œä¸€å€‹):", height=200, placeholder="https://www.facebook.com/share/p/...")

# æŠ“å–å‡½æ•¸
def get_fb_likes_lightweight(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Mobile/15E148 Safari/104.1',
        'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7'
    }
    
    # ä¿®æ­£è™•ï¼šç²¾æº–è½‰æ›ç¶²å€ï¼Œé¿å…å‡ºç¾ m.m.facebook.com
    clean_url = url.strip()
    if "www.facebook.com" in clean_url:
        m_url = clean_url.replace("www.facebook.com", "m.facebook.com")
    elif "facebook.com" in clean_url and "m.facebook.com" not in clean_url:
        m_url = clean_url.replace("facebook.com", "m.facebook.com")
    else:
        m_url = clean_url
    
    try:
        # å¢åŠ  allow_redirects=True è™•ç† FB çš„è½‰å€
        response = requests.get(m_url, headers=headers, timeout=10, allow_redirects=True)
        if response.status_code != 200:
            return f"å­˜å–å¤±æ•— (Code: {response.status_code})"
        
        html_content = response.text
        
        # ç­–ç•¥ 1: å°‹æ‰¾åŒ…å«æ•¸å­—çš„è®šæ•¸æ¨£å¼
        # åŠ å…¥æ›´å¤šå¯èƒ½çš„æ¯”å°æ¨£å¼
        patterns = [
            r'(\d+)\s*å€‹è®š',
            r'(\d+)\s*äººæŒ‰è®š',
            r'(\d+)\s*ä½ä½¿ç”¨è€…',
            r'(\d+)\s*æ¬¡è®š',
            r'>(\d+)\s*<', # æ‰¾å°‹è¢«æ¨™ç±¤åŒ…å¤¾çš„ç´”æ•¸å­—
            r'reactions":\{"count":(\d+)', # æ‰¾å°‹ JSON çµæ§‹ä¸­çš„æ•¸å­—
        ]
        
        for p in patterns:
            match = re.search(p, html_content)
            if match:
                # åªå›å‚³åŒ¹é…åˆ°çš„æ•¸å­—éƒ¨åˆ†ï¼Œè®“è¡¨æ ¼æ›´ä¹¾æ·¨
                found = match.group(0)
                # éæ¿¾æ‰ HTML æ¨™ç±¤
                return re.sub('<[^<]+?>', '', found)
        
        return "æ‰¾ä¸åˆ°æ•¸å­— (éœ€ç™»å…¥æˆ–ç§äººè²¼æ–‡)"
    except Exception as e:
        return f"éŒ¯èª¤: {str(e)}"

# æŒ‰éˆ•å‹•ä½œ
if st.button("é–‹å§‹çµ±æ•´"):
    if urls_input:
        url_list = [u.strip() for u in urls_input.split('\n') if u.strip()]
        results = []
        
        progress_text = st.empty()
        bar = st.progress(0)
        
        for i, url in enumerate(url_list):
            progress_text.text(f"æ­£åœ¨è™•ç†ç¬¬ {i+1}/{len(url_list)} å€‹é€£çµ...")
            count = get_fb_likes_lightweight(url)
            results.append({"é€£çµ": url, "æŠ“å–çµæœ": count})
            bar.progress((i + 1) / len(url_list))
            time.sleep(1.5) # ç¨å¾®å¢åŠ å»¶é²é¿å…è¢«å°é–
            
        st.success("å…¨éƒ¨è™•ç†å®Œç•¢ï¼")
        df = pd.DataFrame(results)
        st.dataframe(df, use_container_width=True) 
        
        # ä¸‹è¼‰ Excel/CSV
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è¼‰çµ±è¨ˆçµæœ (CSV)", data=csv, file_name="fb_likes.csv", mime="text/csv")
    else:
        st.warning("è«‹å…ˆè¼¸å…¥é€£çµã€‚")
